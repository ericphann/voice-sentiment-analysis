{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwTTF55CiKkWrfjunqMlJu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTKisqN_0Nxo",
        "outputId": "1ff44af5-9379-47e2-d63f-f37b6a6d6e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAMJk0u-vR_J",
        "outputId": "709cedcf-750f-4224-aa74-341bd29990ba"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Initialize Whisper Model\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_file_path = \"Audio_Song_Actors_01-24 (1).zip\"\n",
        "output_transcripts = []\n",
        "\n",
        "# Step 1: Extract the ZIP file\n",
        "extract_dir = \"extracted_audio_files\"\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7E-RJBAtLy9",
        "outputId": "de447a05-f922-4110-8709-5f67d2c122b8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Process each audio file\n",
        "for file in Path(extract_dir).rglob('*'):\n",
        "    if file.suffix.lower() in [\".mp3\", \".wav\", \".m4a\"]:  # Supported audio formats\n",
        "        print(f\"Processing: {file.name}\")\n",
        "\n",
        "        # Optional: Convert file to WAV using pydub (if not already in WAV format)\n",
        "        if file.suffix.lower() != \".wav\":\n",
        "            audio = AudioSegment.from_file(file)\n",
        "            file = file.with_suffix(\".wav\")  # Change the file extension to .wav\n",
        "            audio.export(file, format=\"wav\")\n",
        "\n",
        "        # Step 3: Run Whisper\n",
        "        transcription = model.transcribe(str(file))\n",
        "        output_transcripts.append((file.name, transcription['text']))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBLrcKDYtdO_",
        "outputId": "13c61457-6852-4b23-9411-71643ede2ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: 03-02-06-01-01-01-03.wav\n",
            "Processing: 03-02-02-01-02-01-03.wav\n",
            "Processing: 03-02-01-01-01-01-03.wav\n",
            "Processing: 03-02-06-02-01-02-03.wav\n",
            "Processing: 03-02-06-02-02-02-03.wav\n",
            "Processing: 03-02-04-01-01-02-03.wav\n",
            "Processing: 03-02-01-01-02-01-03.wav\n",
            "Processing: 03-02-03-02-02-01-03.wav\n",
            "Processing: 03-02-04-01-01-01-03.wav\n",
            "Processing: 03-02-06-02-01-01-03.wav\n",
            "Processing: 03-02-04-01-02-01-03.wav\n",
            "Processing: 03-02-04-02-02-02-03.wav\n",
            "Processing: 03-02-03-02-02-02-03.wav\n",
            "Processing: 03-02-02-01-01-02-03.wav\n",
            "Processing: 03-02-02-01-01-01-03.wav\n",
            "Processing: 03-02-04-02-01-01-03.wav\n",
            "Processing: 03-02-03-01-01-01-03.wav\n",
            "Processing: 03-02-05-01-02-02-03.wav\n",
            "Processing: 03-02-03-02-01-01-03.wav\n",
            "Processing: 03-02-01-01-01-02-03.wav\n",
            "Processing: 03-02-03-01-02-02-03.wav\n",
            "Processing: 03-02-03-01-02-01-03.wav\n",
            "Processing: 03-02-02-01-02-02-03.wav\n",
            "Processing: 03-02-05-01-01-02-03.wav\n",
            "Processing: 03-02-02-02-02-02-03.wav\n",
            "Processing: 03-02-01-01-02-02-03.wav\n",
            "Processing: 03-02-05-02-02-01-03.wav\n",
            "Processing: 03-02-05-01-01-01-03.wav\n",
            "Processing: 03-02-02-02-01-01-03.wav\n",
            "Processing: 03-02-04-02-01-02-03.wav\n",
            "Processing: 03-02-04-02-02-01-03.wav\n",
            "Processing: 03-02-05-02-01-01-03.wav\n",
            "Processing: 03-02-06-01-02-01-03.wav\n",
            "Processing: 03-02-02-02-02-01-03.wav\n",
            "Processing: 03-02-02-02-01-02-03.wav\n",
            "Processing: 03-02-03-01-01-02-03.wav\n",
            "Processing: 03-02-05-02-01-02-03.wav\n",
            "Processing: 03-02-05-01-02-01-03.wav\n",
            "Processing: 03-02-06-01-01-02-03.wav\n",
            "Processing: 03-02-06-01-02-02-03.wav\n",
            "Processing: 03-02-05-02-02-02-03.wav\n",
            "Processing: 03-02-04-01-02-02-03.wav\n",
            "Processing: 03-02-03-02-01-02-03.wav\n",
            "Processing: 03-02-06-02-02-01-03.wav\n",
            "Processing: 03-02-02-01-01-01-01.wav\n",
            "Processing: 03-02-03-02-01-02-01.wav\n",
            "Processing: 03-02-04-02-02-02-01.wav\n",
            "Processing: 03-02-06-01-01-02-01.wav\n",
            "Processing: 03-02-04-02-01-02-01.wav\n",
            "Processing: 03-02-05-02-02-01-01.wav\n",
            "Processing: 03-02-03-02-02-01-01.wav\n",
            "Processing: 03-02-02-01-02-01-01.wav\n",
            "Processing: 03-02-05-01-01-01-01.wav\n",
            "Processing: 03-02-05-01-01-02-01.wav\n",
            "Processing: 03-02-03-01-02-02-01.wav\n",
            "Processing: 03-02-06-02-02-02-01.wav\n",
            "Processing: 03-02-05-02-01-02-01.wav\n",
            "Processing: 03-02-06-01-02-01-01.wav\n",
            "Processing: 03-02-03-02-02-02-01.wav\n",
            "Processing: 03-02-03-02-01-01-01.wav\n",
            "Processing: 03-02-01-01-01-02-01.wav\n",
            "Processing: 03-02-04-01-02-02-01.wav\n",
            "Processing: 03-02-03-01-01-01-01.wav\n",
            "Processing: 03-02-03-01-02-01-01.wav\n",
            "Processing: 03-02-06-02-01-01-01.wav\n",
            "Processing: 03-02-05-02-01-01-01.wav\n",
            "Processing: 03-02-06-01-01-01-01.wav\n",
            "Processing: 03-02-04-02-01-01-01.wav\n",
            "Processing: 03-02-02-01-02-02-01.wav\n",
            "Processing: 03-02-06-01-02-02-01.wav\n",
            "Processing: 03-02-06-02-01-02-01.wav\n",
            "Processing: 03-02-04-01-01-02-01.wav\n",
            "Processing: 03-02-02-02-01-02-01.wav\n",
            "Processing: 03-02-04-02-02-01-01.wav\n",
            "Processing: 03-02-01-01-01-01-01.wav\n",
            "Processing: 03-02-05-01-02-01-01.wav\n",
            "Processing: 03-02-02-02-01-01-01.wav\n",
            "Processing: 03-02-02-01-01-02-01.wav\n",
            "Processing: 03-02-05-02-02-02-01.wav\n",
            "Processing: 03-02-05-01-02-02-01.wav\n",
            "Processing: 03-02-02-02-02-02-01.wav\n",
            "Processing: 03-02-02-02-02-01-01.wav\n",
            "Processing: 03-02-04-01-02-01-01.wav\n",
            "Processing: 03-02-04-01-01-01-01.wav\n",
            "Processing: 03-02-01-01-02-02-01.wav\n",
            "Processing: 03-02-01-01-02-01-01.wav\n",
            "Processing: 03-02-06-02-02-01-01.wav\n",
            "Processing: 03-02-03-01-01-02-01.wav\n",
            "Processing: 03-02-01-01-02-02-04.wav\n",
            "Processing: 03-02-04-02-01-02-04.wav\n",
            "Processing: 03-02-05-02-01-01-04.wav\n",
            "Processing: 03-02-06-02-01-02-04.wav\n",
            "Processing: 03-02-02-01-02-01-04.wav\n",
            "Processing: 03-02-04-02-02-01-04.wav\n",
            "Processing: 03-02-03-02-02-01-04.wav\n",
            "Processing: 03-02-04-02-01-01-04.wav\n",
            "Processing: 03-02-06-01-02-02-04.wav\n",
            "Processing: 03-02-06-02-02-02-04.wav\n",
            "Processing: 03-02-02-02-01-02-04.wav\n",
            "Processing: 03-02-04-02-02-02-04.wav\n",
            "Processing: 03-02-03-01-01-02-04.wav\n",
            "Processing: 03-02-06-01-01-01-04.wav\n",
            "Processing: 03-02-04-01-01-01-04.wav\n",
            "Processing: 03-02-05-02-02-02-04.wav\n",
            "Processing: 03-02-03-01-02-02-04.wav\n",
            "Processing: 03-02-05-01-02-02-04.wav\n",
            "Processing: 03-02-01-01-01-02-04.wav\n",
            "Processing: 03-02-03-01-02-01-04.wav\n",
            "Processing: 03-02-03-02-01-02-04.wav\n",
            "Processing: 03-02-05-01-01-01-04.wav\n",
            "Processing: 03-02-05-02-02-01-04.wav\n",
            "Processing: 03-02-04-01-01-02-04.wav\n",
            "Processing: 03-02-02-02-01-01-04.wav\n",
            "Processing: 03-02-03-02-01-01-04.wav\n",
            "Processing: 03-02-02-02-02-02-04.wav\n",
            "Processing: 03-02-05-01-01-02-04.wav\n",
            "Processing: 03-02-03-02-02-02-04.wav\n",
            "Processing: 03-02-04-01-02-01-04.wav\n",
            "Processing: 03-02-04-01-02-02-04.wav\n",
            "Processing: 03-02-06-01-02-01-04.wav\n",
            "Processing: 03-02-02-02-02-01-04.wav\n",
            "Processing: 03-02-06-02-02-01-04.wav\n",
            "Processing: 03-02-01-01-02-01-04.wav\n",
            "Processing: 03-02-03-01-01-01-04.wav\n",
            "Processing: 03-02-02-01-01-01-04.wav\n",
            "Processing: 03-02-01-01-01-01-04.wav\n",
            "Processing: 03-02-05-01-02-01-04.wav\n",
            "Processing: 03-02-05-02-01-02-04.wav\n",
            "Processing: 03-02-06-01-01-02-04.wav\n",
            "Processing: 03-02-02-01-01-02-04.wav\n",
            "Processing: 03-02-06-02-01-01-04.wav\n",
            "Processing: 03-02-02-01-02-02-04.wav\n",
            "Processing: 03-02-02-01-02-02-10.wav\n",
            "Processing: 03-02-03-01-01-01-10.wav\n",
            "Processing: 03-02-04-01-02-02-10.wav\n",
            "Processing: 03-02-03-02-02-01-10.wav\n",
            "Processing: 03-02-03-02-01-02-10.wav\n",
            "Processing: 03-02-05-01-02-02-10.wav\n",
            "Processing: 03-02-05-01-01-02-10.wav\n",
            "Processing: 03-02-05-01-01-01-10.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Save or Print the Transcriptions\n",
        "output_file = \"transcriptions.txt\"\n",
        "with open(output_file, 'w') as f:\n",
        "    for filename, text in output_transcripts:\n",
        "        f.write(f\"{filename}:\\n{text}\\n\\n\")\n",
        "\n",
        "print(f\"Transcriptions saved to {output_file}\")"
      ],
      "metadata": {
        "id": "kBz67_hLthLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('transcriptions.txt')\n"
      ],
      "metadata": {
        "id": "iSLje4Eo0GVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# File path to your text file\n",
        "file_path = \"transcriptions.txt\"\n",
        "\n",
        "# Dictionary to store results\n",
        "classifications = {}\n",
        "\n",
        "# Define a classification function\n",
        "def classify_tone(text):\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Read and classify the text file\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if line and \":\" in line:  # Ensure the line contains valid data\n",
        "            filename, transcription = line.split(\":\", 1)\n",
        "            filename = filename.strip()\n",
        "            transcription = transcription.strip()\n",
        "            tone = classify_tone(transcription)  # Classify the transcription\n",
        "            classifications[filename] = {\"transcription\": transcription, \"tone\": tone}\n",
        "\n",
        "# Print the results\n",
        "for filename, data in classifications.items():\n",
        "    print(f\"Filename: {filename}\\nTranscription: {data['transcription']}\\nTone: {data['tone']}\\n\")\n",
        "\n",
        "# Optional: Save results to a new file\n",
        "output_file = \"classified_transcriptions.txt\"\n",
        "with open(output_file, 'w') as f:\n",
        "    for filename, data in classifications.items():\n",
        "        f.write(f\"{filename}:\\n{data['transcription']} ({data['tone']})\\n\\n\")\n"
      ],
      "metadata": {
        "id": "WMEQsG5u5irC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_V8zX76EzZMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Define function for sentiment classification\n",
        "def classify_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    polarity = analysis.sentiment.polarity  # Polarity ranges from -1 (negative) to +1 (positive)\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Example transcriptions\n",
        "transcriptions = {\n",
        "    \"03-02-06-01-01-01-03.wav\": \"Kids are talking by the door.\",\n",
        "    \"03-02-02-01-02-01-03.wav\": \"Dogs are sitting by the door.\"\n",
        "}\n",
        "\n",
        "# Classify each transcription\n",
        "for file, text in transcriptions.items():\n",
        "    sentiment = classify_sentiment(text)\n",
        "    print(f\"File: {file}\\nTranscription: {text}\\nSentiment: {sentiment}\\n\")\n"
      ],
      "metadata": {
        "id": "BCJTDlg40J0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained sentiment analysis model\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Example transcriptions\n",
        "transcriptions = [\n",
        "    \"Kids are talking by the door.\",\n",
        "    \"Dogs are sitting by the door.\"\n",
        "]\n",
        "\n",
        "# Analyze sentiment\n",
        "for text in transcriptions:\n",
        "    result = sentiment_analyzer(text)[0]\n",
        "    print(f\"Text: {text}\\nSentiment: {result['label']} (Score: {result['score']:.2f})\\n\")\n"
      ],
      "metadata": {
        "id": "Zx2xIFvi1xix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2mzt_AaR2xQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"03-02-01-01-01-01-01.wav\",verbose=True)\n",
        "result['text']"
      ],
      "metadata": {
        "id": "SgUacg1p03Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, seg in enumerate(result['segments']):\n",
        "  print(f'[{i}]',seg['text'])"
      ],
      "metadata": {
        "id": "St6SGMh01n2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(result['segments'])\n",
        "df"
      ],
      "metadata": {
        "id": "e8HGp6na18r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = whisper.load_audio(\"03-02-01-01-01-01-01.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "_, probs = model.detect_language(mel)"
      ],
      "metadata": {
        "id": "I46r_Dp62Y5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(probs.items(), key=lambda x:x[1], reverse=True)[:10]"
      ],
      "metadata": {
        "id": "OkZ-8Rlj2rd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "r1PilY8y3V7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg"
      ],
      "metadata": {
        "id": "T20s7qGs7xjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}